{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid token (<ipython-input-2-f897292f1762>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-f897292f1762>\"\u001b[1;36m, line \u001b[1;32m36\u001b[0m\n\u001b[1;33m    fifaEarliestRelease = 07\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid token\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import urllib\n",
    "import sys\n",
    "import collections\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from time import strptime\n",
    "import time\n",
    "import re\n",
    "from footballData.items import Player\n",
    "from googleapiclient.discovery import build\n",
    "import pprint\n",
    "\n",
    "class PlayerSpider(scrapy.Spider):\n",
    "    name = \"player\"\n",
    "    myGoogleApiKey = \"AIzaSyCq89KQUzX5ShZiqBEmtOjnmCFPGIN8bi4\"\n",
    "    myGoogleCseId = \"007327452172099429540:1bhg1zcqlyw\"\n",
    "    searchEngine = None\n",
    "    #'Google'\n",
    "    #'http://www.bing.com/search?q='\n",
    "    #'http://uk.search.yahoo.com/search?p='\n",
    "    firstPlayerIndex = 1 # Where to start looping players on the list provided\n",
    "    lastPlayerIndex = 8 # Where to end the loop\n",
    "    searchEngineResultLimit = 3\n",
    "    parseSoFifaLinkFromFile = False\n",
    "    birthDayCheck = False\n",
    "    birthMonthCheck = False \n",
    "    birthYearCheck = False\n",
    "    countryCheck = False\n",
    "    parseLastNameOnly = False\n",
    "    playerFilePath = '/Users/hugomathien/Documents/workspace/footballData/players_list/1_players_list_all.txt'\n",
    "    playerErrorFile = '/Users/hugomathien/Documents/workspace/footballData/players_list/fail.txt'\n",
    "    baseUrlSoFifa = 'http://sofifa.com/players?keyword='\n",
    "    baseUrlLiveScore = 'http://football-data.mx-api.enetscores.com/page/xhr/player/'\n",
    "    fifaLatestRelease=16\n",
    "    fifaEarliestRelease = 07\n",
    "    fifaFirstStatsTimestamp = 154994 #22 February 2007\n",
    "    allowed_domains = [\"http://sofifa.com\",\n",
    "                       \"sofifa.com\",\n",
    "                       \"http://www.sofifa.com\",\n",
    "                       \"http://sofifa.com/\",\n",
    "                       \"sofifa.com/\",\n",
    "                       \"http://www.sofifa.com/\",\n",
    "                       \"http://sofifa.com/player\",\n",
    "                       \"sofifa.com/player\",\n",
    "                       \"http://www.sofifa.com/player\",\n",
    "                       \"football-data.mx-api.enetscores.com\",\n",
    "                       'json.mx-api.enetscores.com',\n",
    "                       \"football-data.mx-api.enetscores.com/page/xhr/player/\",\n",
    "                       \"http://uk.search.yahoo.com/search\",\n",
    "                       \"http://uk.search.yahoo.com/\",\n",
    "                       \"https://www.googleapis.com/customsearch/\"]\n",
    "    start_urls = [\n",
    "    \"http://sofifa.com/\",\n",
    "    ]\n",
    "    \n",
    "    def googleSearch(self,search_term, api_key, cse_id, **kwargs):\n",
    "        service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "        res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()\n",
    "        return res['items']\n",
    "    \n",
    "    #Calculate the age of the player with respect to the number on Sofifa website\n",
    "    def calculateAge(self,end,born):\n",
    "        start = 154994\n",
    "        startDateFifa = datetime(2007,2,22)\n",
    "        delta = end - start\n",
    "        date = startDateFifa + timedelta(days=delta)\n",
    "        return date.year - born.year - ((date.month, date.day) < (born.month, born.day))\n",
    "\n",
    "    #Read players in the file \n",
    "    def parse(self, response):\n",
    "        playerFile = open(self.playerFilePath,'U')\n",
    "        with playerFile:\n",
    "            playerIndex = self.firstPlayerIndex-1\n",
    "            lines=playerFile.readlines()\n",
    "            while playerIndex <= (self.lastPlayerIndex-1):\n",
    "                line = lines[playerIndex]\n",
    "                line = line.rstrip()\n",
    "                comma = line.find(',')\n",
    "                matchId = line[:comma]\n",
    "                line = line[comma+1:]\n",
    "                comma = line.find(',')\n",
    "                \n",
    "                if self.parseSoFifaLinkFromFile:\n",
    "                    comma = line.find(',')\n",
    "                    playerName = line[:comma]\n",
    "                    url = line[comma+1:]\n",
    "                    playerIndex += 1\n",
    "                    fifaIdList = re.findall('sofifa.com/player/([0-9]+)',url)\n",
    "                    fifaId = fifaIdList[0]\n",
    "                    #url = 'http://sofifa.com/player/' + fifaId\n",
    "                    yield scrapy.Request(url, \n",
    "                                         callback=self.parsePlayerFromSoFifa,\n",
    "                                         dont_filter = True,\n",
    "                                         meta={'dont_redirect': True,\n",
    "                                               'handle_httpstatus_list': [302],\n",
    "                                               'fifaVersion':self.fifaLatestRelease,'playerIndex':playerIndex,\n",
    "                                               'playerUrl':url,'playerName':playerName,'matchId': matchId,\n",
    "                                               'fifaId':fifaId,'birthDay':0,'birthMonth':0,'birthYear':0,'country':'none'})\n",
    "                else:\n",
    "                    if comma > -1:\n",
    "                        line = line[:comma]\n",
    "                    playerName = line\n",
    "                    url = self.baseUrlLiveScore + matchId\n",
    "                    playerIndex += 1\n",
    "                    yield scrapy.Request(url, \n",
    "                                         callback=self.parsePlayerBirthdayFromLivescore,\n",
    "                                         meta={'playerName':playerName,'matchId':matchId})\n",
    "                \n",
    "    #Parse the player's birthday from the same website where we got the match squad ('football livescore')\n",
    "    def parsePlayerBirthdayFromLivescore(self,response):\n",
    "        playerName = response.meta['playerName']\n",
    "        matchId = response.meta['matchId']\n",
    "        try:\n",
    "            birthday = response.xpath('//span[@class=\"mx-break-small\"]/text()').re_first(\"\\((.+)\\)\")\n",
    "            dataList = response.xpath('//span[@class=\"mx-break-small\"]/text()').extract()\n",
    "            country = dataList[3]\n",
    "            if birthday is not None:\n",
    "                delimit1 = birthday.find('/') + 1\n",
    "                delimit2 = birthday.find('-') + 1\n",
    "                birthMonth = birthday[delimit1:delimit1+2]\n",
    "                birthDay = birthday[:2]\n",
    "                birthYear = birthday[delimit2:len(birthday)]\n",
    "            else:\n",
    "                birthMonth = 0\n",
    "                birthDay = 0\n",
    "                birthYear = 0\n",
    "                \n",
    "            if self.parseLastNameOnly:\n",
    "                    nameSpace = playerName.find(' ')\n",
    "                    if nameSpace > -1:\n",
    "                        playerLastName = playerName.rsplit(None, 1)[-1]\n",
    "                        playerNameEncoded = urllib.quote(playerLastName, safe='')\n",
    "            else:\n",
    "                playerNameEncoded = urllib.quote(playerName, safe='')\n",
    "            \n",
    "            # Search for the player via a search engine or directly via sofifa.com\n",
    "            if self.searchEngine is not None:           \n",
    "                if self.searchEngine == 'Google':\n",
    "                    results = self.googleSearch(playerName + ' site:sofifa.com/player', self.myGoogleApiKey, self.myGoogleCseId, num=1)\n",
    "                    firstResult = results[0]\n",
    "                    googleSearchUrl = firstResult['formattedUrl']\n",
    "                    fifaIdList = re.findall('sofifa.com/player/([0-9]+)',googleSearchUrl)\n",
    "                    fifaId = fifaIdList[0]\n",
    "                    playerUrl = 'http://sofifa.com/player/' + str(fifaId)\n",
    "                    yield scrapy.Request(playerUrl, callback=self.parsePlayerFromSoFifa,dont_filter = True,\n",
    "                                     meta={'fifaVersion':self.fifaEarliestRelease,'playerIndex':0,\n",
    "                                           'playerUrl':playerUrl,'playerName':playerName,'matchId': matchId,\n",
    "                                           'fifaId':fifaId,'birthDay':birthDay,'birthMonth':birthMonth,'birthYear':birthYear,'country':country})\n",
    "                else:\n",
    "                    playerUrl = self.searchEngine + playerNameEncoded + ' sofifa.com/player'\n",
    "                    playerUrlWithFifaVersion = playerUrl\n",
    "                    yield scrapy.Request(playerUrlWithFifaVersion, \n",
    "                                         callback=self.parsePlayerFromSearchEngine,\n",
    "                                         dont_filter=True,\n",
    "                                         meta={'fifaVersion':self.fifaLatestRelease,'playerUrl':playerUrl,\n",
    "                                               'playerName':playerName,'matchId':matchId,'birthDay':birthDay,\n",
    "                                               'birthMonth':birthMonth,'birthYear':birthYear,'country':country})\n",
    "            else:\n",
    "                playerUrl = self.baseUrlSoFifa + playerNameEncoded\n",
    "                playerUrlWithFifaVersion = playerUrl + '&v=' + str(self.fifaLatestRelease) \n",
    "                yield scrapy.Request(playerUrlWithFifaVersion, callback=self.parsePlayer,\n",
    "                                     dont_filter=True,\n",
    "                                     meta={'fifaVersion':self.fifaLatestRelease,'playerUrl':playerUrl,\n",
    "                                           'playerName':playerName,'matchId':matchId,'birthDay':birthDay,\n",
    "                                           'birthMonth':birthMonth,'birthYear':birthYear,'country':country}) \n",
    "        except:\n",
    "            print 'Failed retrieving: ' + playerName\n",
    "            filename = self.playerErrorFile\n",
    "            file = open(filename, 'a')\n",
    "            file.write(matchId + ',' + playerName + '\\n')\n",
    "    \n",
    "    def parsePlayerFromSearchEngine(self,response):\n",
    "        matchId = response.meta['matchId']\n",
    "        fifaVersion = response.meta['fifaVersion']\n",
    "        playerUrl = response.meta['playerUrl']\n",
    "        playerName = response.meta['playerName']\n",
    "        birthDay = response.meta['birthDay']\n",
    "        birthMonth = response.meta['birthMonth']\n",
    "        birthYear = response.meta['birthYear']\n",
    "        country = response.meta['country']\n",
    "        playerIndex = 0\n",
    "        \n",
    "        fifaIdList = response.xpath('//a/@href').re('sofifa.com/player/([0-9]+)')\n",
    "        fullHrefLink = response.xpath('//a/@href').re('sofifa.com/player/(.+)')\n",
    "        \n",
    "        idx = 0\n",
    "        for fifaId in fifaIdList[:self.searchEngineResultLimit]:\n",
    "            url = 'http://sofifa.com/player/' + fullHrefLink[idx]+'?hl=en-US'\n",
    "            yield scrapy.Request(url, \n",
    "                                 callback=self.parsePlayerFromSoFifa,\n",
    "                                 dont_filter = True,\n",
    "                                 meta={'fifaVersion':fifaVersion,'playerIndex':playerIndex,\n",
    "                                       'playerUrl':playerUrl,'playerName':playerName,'matchId': matchId,\n",
    "                                       'fifaId':fifaId,'birthDay':birthDay,'birthMonth':birthMonth,'birthYear':birthYear,'country':country})\n",
    "            idx += 1\n",
    "            \n",
    "    # Go to Sofifa website and search the player\n",
    "    def parsePlayer(self,response):\n",
    "        matchId = response.meta['matchId']\n",
    "        fifaVersion = response.meta['fifaVersion']\n",
    "        playerUrl = response.meta['playerUrl']\n",
    "        playerName = response.meta['playerName']\n",
    "        birthDay = response.meta['birthDay']\n",
    "        birthMonth = response.meta['birthMonth']\n",
    "        birthYear = response.meta['birthYear']\n",
    "        country = response.meta['country']\n",
    "        \n",
    "        hrefList =  response.xpath('//a[contains(@href,\"/player/\")]/@href').extract()\n",
    "        playerList =  response.xpath('//a[contains(@href,\"/player/\")]/@title').extract()\n",
    "        \n",
    "        # Get the next player in the list or start from zero if we are doing a new search\n",
    "        try:\n",
    "            playerIndex = response.meta[\"playerIndex\"] + 1\n",
    "        except:\n",
    "            playerIndex = 0\n",
    "        \n",
    "        # If there is no relevant player in the search result, decrement the version of fifa used for the search\n",
    "        if ((playerIndex+1 > len(hrefList)) or (not playerList)) and fifaVersion > self.fifaEarliestRelease:\n",
    "            fifaVersion -= 1\n",
    "            if len(str(fifaVersion)) == 1:\n",
    "                fifaVersionStr = '0'+str(fifaVersion)\n",
    "            else:\n",
    "                fifaVersionStr = str(fifaVersion)\n",
    "            \n",
    "            # Fire a new search for an older version of fifa\n",
    "            playerUrlWithFifaVersion = playerUrl + '&v=' + fifaVersionStr + '&hl=en-US'\n",
    "            yield scrapy.Request(playerUrlWithFifaVersion, \n",
    "                                 callback=self.parsePlayer,\n",
    "                                 dont_filter = True,\n",
    "                                 meta={'fifaVersion':fifaVersion,'playerUrl':playerUrl,\n",
    "                                       'playerName':playerName,'matchId':matchId,'birthDay':birthDay,\n",
    "                                       'birthMonth':birthMonth,'birthYear':birthYear,'country':country})\n",
    "        # Browse relevant players\n",
    "        elif (playerIndex+1 <= len(hrefList)):\n",
    "            try:\n",
    "                href = hrefList[playerIndex]\n",
    "                allFifaId = re.findall(\"player/([0-9]+)\", href)\n",
    "                fifaId = allFifaId[0]\n",
    "                url = 'http://sofifa.com' + str(href)\n",
    "                # Look at the player's page\n",
    "                yield scrapy.Request(url, \n",
    "                                     callback=self.parsePlayerFromSoFifa,\n",
    "                                     dont_filter = True,\n",
    "                                     meta={'fifaVersion':fifaVersion,'playerIndex':playerIndex,\n",
    "                                           'playerUrl':playerUrl,'playerName':playerName,'matchId': matchId,\n",
    "                                           'fifaId':fifaId,'birthDay':birthDay,'birthMonth':birthMonth,'birthYear':birthYear,'country':country})\n",
    "            except:\n",
    "                e = sys.exc_info()[0]\n",
    "                print 'Error with player: ' + playerName + ' Error type: ' + str(e)\n",
    "        # If we haven't found the player after browsing all versions of fifa, write out the player's in a file\n",
    "        else:\n",
    "            print 'No player found in Sofifa for: ' + playerName\n",
    "            filename = self.playerErrorFile\n",
    "            file = open(filename, 'a')\n",
    "            file.write(matchId + ',' + playerName + '\\n')\n",
    "            \n",
    "    # Read the player page on sofifa and reach the page of the latest stats update\n",
    "    def parsePlayerFromSoFifa(self, response): \n",
    "        fifaVersion = response.meta[\"fifaVersion\"]\n",
    "        playerIndex = response.meta[\"playerIndex\"]\n",
    "        playerUrl = response.meta[\"playerUrl\"]\n",
    "        playerName = response.meta['playerName']\n",
    "        matchId = response.meta['matchId']\n",
    "        fifaId = response.meta['fifaId']\n",
    "        country = response.meta['country']\n",
    "        \n",
    "        #Livescore birhtday\n",
    "        birthDay = int(response.meta['birthDay'])\n",
    "        birthMonth = int(response.meta['birthMonth'])\n",
    "        birthYear = int(response.meta['birthYear'])\n",
    "\n",
    "        countrySoFifa = response.xpath('//div[@class=\"content\"]//div[@class=\"meta\"]//a/text()').extract_first()\n",
    "        \n",
    "        #Sofifa birthday\n",
    "        birthdaySoFifa = response.xpath('//div[@class=\"tab-content\"]//div[@class=\"description\"]/p/text()').re_first('\\((.+)\\)') #Sep 9, 1991\n",
    "        if birthdaySoFifa is None:\n",
    "            print 'Cannot find birthday for sofifa id ' +str(fifaId)\n",
    "            soFifaBirthMonth = birthMonth\n",
    "            soFifaBirthDay = birthDay\n",
    "            soFifaBirthYear = birthYear\n",
    "        else: \n",
    "            if birthdaySoFifa.find('/') > -1:\n",
    "                slash = birthdaySoFifa.find('/')\n",
    "                soFifaBirthDay = int(birthdaySoFifa[:slash])\n",
    "                birthDayCut = birthdaySoFifa[slash+1:]\n",
    "                slash = birthDayCut.find('/')\n",
    "                soFifaBirthMonth = int(birthDayCut[:slash])\n",
    "                soFifaBirthYear = int(birthDayCut[slash+1:len(birthDayCut)])\n",
    "            else:\n",
    "                comma = birthdaySoFifa.find(',') + 1\n",
    "                try:\n",
    "                    soFifaBirthYear = int(birthdaySoFifa[-4:])\n",
    "                except:\n",
    "                    soFifaBirthYear = birthYear\n",
    "                try:\n",
    "                    soFifaBirthDay = int(birthdaySoFifa[4:comma-1])\n",
    "                except:\n",
    "                    soFifaBirthDay = birthDay\n",
    "                try:\n",
    "                    soFifaBirthMonthTxt = birthdaySoFifa[:3]\n",
    "                    soFifaBirthMonth = strptime(soFifaBirthMonthTxt,'%b').tm_mon\n",
    "                except:\n",
    "                    soFifaBirthMonth = birthMonth\n",
    "                    \n",
    "                    \n",
    "        # Compare birthdays\n",
    "        \n",
    "        if self.birthDayCheck and birthDay != 0:\n",
    "            birthdaybool = (soFifaBirthDay == birthDay)\n",
    "        else:\n",
    "            birthdaybool = True\n",
    "        \n",
    "        if self.birthMonthCheck and birthMonth != 0:\n",
    "            birthmonthbool = (soFifaBirthMonth == birthMonth)\n",
    "        else:\n",
    "            birthmonthbool = True\n",
    "        \n",
    "        if self.birthYearCheck and birthYear != 0:\n",
    "            birthyearbool = (soFifaBirthYear == birthYear)\n",
    "        else:\n",
    "            birthyearbool = True\n",
    "        \n",
    "        if self.countryCheck:\n",
    "            if countrySoFifa.find(country) > -1:\n",
    "                countrybool = True\n",
    "            else:\n",
    "                countrybool = False\n",
    "            #countrybool = (country == countrySoFifa)\n",
    "        else:\n",
    "            countrybool = True\n",
    "\n",
    "        if(birthmonthbool and birthdaybool and birthyearbool and countrybool):\n",
    "            href = response.xpath('//dt/a/@href').extract_first() # Get the latest update page\n",
    "            url = 'http://sofifa.com' + str(href)\n",
    "            yield scrapy.Request(url, callback=self.recordPlayer,\n",
    "                                 dont_filter = True,\n",
    "                                 meta={'playerIndex':playerIndex,'playerUrl':playerUrl,\n",
    "                                       'playerName':playerName,'matchId': matchId,\n",
    "                                       'fifaId':fifaId,'birthdaySoFifa':birthdaySoFifa,'country':country})\n",
    "            #Go to latest player update page\n",
    "        elif self.searchEngine is not None:\n",
    "            pass\n",
    "        else:\n",
    "            if len(str(fifaVersion)) == 1:\n",
    "                fifaVersionStr = '0'+str(fifaVersion)\n",
    "            else:\n",
    "                fifaVersionStr = str(fifaVersion)\n",
    "            playerUrlWithVersion = playerUrl + '&v=' + fifaVersionStr + '&hl=en-US'\n",
    "            yield scrapy.Request(playerUrlWithVersion, callback=self.parsePlayer,dont_filter = True,\n",
    "                                 meta={'fifaVersion':fifaVersion,'playerIndex':playerIndex,\n",
    "                                       'playerUrl':playerUrl,'playerName':playerName,'matchId':matchId,\n",
    "                                       'birthDay':birthDay,'birthMonth':birthMonth,'birthYear':birthYear,'country':country})\n",
    "            \n",
    "    # Read and dump the player stats includings previous updates\n",
    "    def recordPlayer(self,response):\n",
    "        try:\n",
    "            playerIndex = response.meta[\"playerIndex\"]\n",
    "            playerUrl = response.meta[\"playerUrl\"]\n",
    "            playerName = response.meta['playerName']\n",
    "            matchId = response.meta['matchId']\n",
    "            fifaId = response.meta['fifaId']\n",
    "            birthdaySoFifa = response.meta['birthdaySoFifa']\n",
    "            timestamp = response.xpath('//dt/a/@href').re('e=([0-9]+)')\n",
    "            name = response.xpath('//div[@class=\"header\"]/text()').re_first('(.+) \\(ID:')\n",
    "            generalStats = response.xpath('//div[@class=\"cards\"]//div[@class=\"card\"]//div[@class=\"content\"]//ul/li/span/text()').extract()\n",
    "            statsValues = response.xpath('//div[@class=\"description\"]/ul/li/span[contains(@class,\"p \")]/text()').extract()\n",
    "            statsLabels = response.xpath('//div[@class=\"description\"]/ul/li/text()').re('\\t+([^\\t]+)\\t+')     \n",
    "            updates  = response.xpath('//dd')\n",
    "            feet = response.xpath('//div[@class=\"tab-content\"]//div[@class=\"description\"]/p/text()').re_first('([0-9]+)\\'')\n",
    "            inch = response.xpath('//div[@class=\"tab-content\"]//div[@class=\"description\"]/p/text()').re_first('\\'([0-9]+)')\n",
    "            weight = response.xpath('//div[@class=\"tab-content\"]//div[@class=\"description\"]/p/text()').re('([0-9]+)lbs')\n",
    "            weight = weight[0]\n",
    "            height = (float(feet) * 12 + float(inch)) * 2.54\n",
    "            overallRating = generalStats[0]\n",
    "            potential = generalStats[1]\n",
    "            workRate = generalStats[2]\n",
    "            if not potential.isdigit():\n",
    "                potential = generalStats[2]\n",
    "                \n",
    "            idx = 2\n",
    "            while workRate.find('/') == -1 and idx <= 4 and idx < len(workRate):\n",
    "                workRate = generalStats[idx]\n",
    "                idx += 1\n",
    "            \n",
    "            delimitor = workRate.find('/')\n",
    "            attackingWorkRate = workRate[:delimitor-1]\n",
    "            defensiveWorkRate = workRate[delimitor+2:]\n",
    "            preferredFoot = response.xpath('//div[@class=\"cards\"]//div[@class=\"card\"]//div[@class=\"content\"]//ul/li/text()').re('\\t+([^\\t]+)\\t+') \n",
    "            # Work out the latest stats\n",
    "            currentStats = collections.OrderedDict()\n",
    "            currentStats['Timestamp'] = timestamp[0]\n",
    "            currentStats['Overall rating'] = overallRating\n",
    "            currentStats['Potential'] = potential\n",
    "            currentStats['Preferred Foot'] = preferredFoot[0]\n",
    "            currentStats['Attacking Work Rate'] = attackingWorkRate\n",
    "            currentStats['Defensive Work Rate'] = defensiveWorkRate\n",
    "            for i,label in enumerate(statsLabels):\n",
    "                currentStats[label] = statsValues[i]\n",
    "            \n",
    "    \n",
    "            #stats = collections.OrderedDict()\n",
    "            #stats[timestamp[0]] = currentStats\n",
    "            \n",
    "            stats = list()\n",
    "            stats.append(currentStats)\n",
    "            \n",
    "            player = Player()  \n",
    "            player['name'] = playerName\n",
    "            player['matchId'] = matchId\n",
    "            player['fifaId'] = fifaId\n",
    "            player['birthday'] = birthdaySoFifa\n",
    "            player['height'] = height\n",
    "            player['weight'] = weight\n",
    "            \n",
    "            # Work out the previous stats from the update timeline\n",
    "            for i, update in enumerate(updates):\n",
    "                currentStats = collections.OrderedDict(currentStats)\n",
    "                preferredFoot = update.xpath('span[@class=\"nowrap\"]').re('<abbr>Preferred Foot:</abbr> ([A-Z]+[a-z]+) <i')\n",
    "                attackingWorkRate = update.xpath('span[@class=\"nowrap\"]').re('<abbr>Attacking Work Rate:</abbr> ([A-Z]+[a-z]+) <i')\n",
    "                defensiveWorkRate = update.xpath('span[@class=\"nowrap\"]').re('<abbr>Defensive Work Rate:</abbr> ([A-Z]+[a-z]+) <i')\n",
    "                if len(preferredFoot) == 1:\n",
    "                    currentStats['Preferred Foot'] = preferredFoot[0]\n",
    "                if len(attackingWorkRate) == 1:\n",
    "                    currentStats['Attacking Work Rate'] = attackingWorkRate[0]\n",
    "                if len(defensiveWorkRate) == 1:\n",
    "                    currentStats['Defensive Work Rate'] = defensiveWorkRate[0]\n",
    "                \n",
    "                labels = update.xpath('span[@class=\"nowrap\"]').re('<abbr>(.+):</abbr> <span class=\"p ')\n",
    "                values = update.xpath('span[@class=\"nowrap\"]/span[contains(@class,\"p \")]/text()').extract()\n",
    "                if i < (len(updates)-1): # all updates\n",
    "                    currentStats['Timestamp'] = timestamp[i+1]\n",
    "                else:\n",
    "                    currentStats['Timestamp'] = self.fifaFirstStatsTimestamp\n",
    "                for j,label in enumerate(labels):\n",
    "                    currentStats[label] = values[2*j]\n",
    "              \n",
    "                stats.append(currentStats)\n",
    "                    #stats[timestamp[i+1]] = currentStats\n",
    "    \n",
    "            # Dump stats\n",
    "            player['stats'] = stats\n",
    "            yield player\n",
    "            \n",
    "            print 'Exported ' + name + ',' + matchId + ',' + fifaId\n",
    "            filename = '/Users/hugomathien/Documents/workspace/footballData/players_list/2_export_list.txt'\n",
    "            file = open(filename, 'a')\n",
    "            file.write(name + ',' + matchId + ',' + fifaId + '\\n')\n",
    "        except:\n",
    "            print 'No player found in Sofifa for: ' + playerName\n",
    "            filename = self.playerErrorFile\n",
    "            file = open(filename, 'a')\n",
    "            file.write(matchId + ',' + playerName + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
